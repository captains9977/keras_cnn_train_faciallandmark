{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hBnD3V2CuaD5"
   },
   "outputs": [],
   "source": [
    "#####  LOADING AND EXTRACTING DATA   #####\n",
    "\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline\n",
    "def data_loader2():\n",
    "    \n",
    "    # Load dataset file\n",
    "    data_frame = pd.read_csv('training.csv')\n",
    "    \n",
    "    data_frame['Image'] = data_frame['Image'].apply(lambda i: np.fromstring(i, sep=' '))\n",
    "    data_frame = data_frame.dropna()  # Get only the data with 15 keypoints\n",
    "   \n",
    "    # Extract Images pixel values\n",
    "    imgs_array = np.vstack(data_frame['Image'].values)/ 255.0\n",
    "    imgs_array = imgs_array.astype(np.float32)    # Normalize, target values to (0, 1)\n",
    "    imgs_array = imgs_array.reshape(-1, 96, 96, 1)\n",
    "        \n",
    "    # Extract labels (key point cords)\n",
    "    labels_array = data_frame[data_frame.columns[:-1]].values\n",
    "    labels_array = (labels_array - 48) / 48    # Normalize, traget cordinates to (-1, 1)\n",
    "    labels_array = labels_array.astype(np.float32) \n",
    "    \n",
    "    # shuffle the train data\n",
    "#     imgs_array, labels_array = shuffle(imgs_array, labels_array, random_state=9)  \n",
    "    \n",
    "    return imgs_array, labels_array\n",
    "\n",
    "def data_loader(path):\n",
    "    data_frame = pd.read_csv(path)\n",
    "    # Extract images\n",
    "    data_frame['image'] = data_frame['image'].apply(lambda i: np.fromstring(i, sep=' '))\n",
    "    data_frame = data_frame.dropna()  # Get only the data with 15 keypoints\n",
    "    imgs_array = np.vstack(data_frame['image'].values)/255.0\n",
    "    imgs_array = imgs_array.astype(np.float32)    # Normalize, target values to (0, 1)\n",
    "    imgs_array = imgs_array.reshape(-1, 128, 128, 1)\n",
    "    # Extract labels (key point cords)\n",
    "    labels_array = data_frame[data_frame.columns[:-1]].values\n",
    "#     labels_array = (labels_array - 64) / 64    # Normalize, traget cordinates to (-1, 1)\n",
    "    labels_array = (labels_array)     # Normalize, traget cordinates to (-1, 1)\n",
    "    labels_array = labels_array.astype(np.float32)\n",
    "#     shuffle the train data\n",
    "    imgs_array, labels_array = shuffle(imgs_array, labels_array, random_state=9)  \n",
    "    return imgs_array,labels_array\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n=7\n",
    "# labels[n] = (labels[n]*48)+48\n",
    "# print(labels[n])\n",
    "# image = np.squeeze(imgs[n])\n",
    "# plt.imshow(image, cmap='gray')\n",
    "# plt.plot(labels[n][::2], labels[n][1::2], 'ro')\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QzUVeVykvF6f",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "######   BUILD, TRAIN AND SAVE THE CONVOLUTIONAL MODEL    ########\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D, Activation\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "# from tensorflow.keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, History\n",
    "from tensorflow.keras.regularizers import l2\n",
    "# from keras.optimizers import Adam\n",
    "# X_train.shape\n",
    "\n",
    "# Main model\n",
    "def the_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Layer 1 \n",
    "    model.add(Conv2D(32, (3,3),padding='same',activation='relu',input_shape=X_train.shape[1:])) \n",
    "    model.add(MaxPooling2D(pool_size=2)) ## 64*64\n",
    "    \n",
    "    # Layer 2\n",
    "    model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2)) ## 32*32\n",
    "    \n",
    "    # Layer 3\n",
    "    model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2)) ## 16*16\n",
    "    \n",
    "    # Layer 4\n",
    "    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2)) ## 8*8\n",
    "    \n",
    "    # Layer 5\n",
    "    model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2)) ## 4*4\n",
    "    \n",
    "    # Layer 6\n",
    "    model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2)) ## 2*2\n",
    "    \n",
    "    # Layer 7\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2048, activation='relu'))\n",
    "    model.add(Dense(2048, activation='relu'))\n",
    "#     model.add(Dropout(0.2))\n",
    "    model.add(Dense(196)) ## 68 facial landmarks points\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training datapoint shape: X_train.shape:(10000, 128, 128, 1)\n",
      "Training labels shape: y_train.shape:(10000, 196)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = data_loader(\"training_sets/train_98_2.csv\")\n",
    "print(\"Training datapoint shape: X_train.shape:{}\".format(X_train.shape))\n",
    "print(\"Training labels shape: y_train.shape:{}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "model = the_model()\n",
    "hist = History()\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='checkpoints/checkpoint_128_9.hdf5', \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "from datetime import datetime\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# file_writer = tf.summary.create_file_writer(logdir + \"/metrics\")\n",
    "# file_writer.set_as_default()\n",
    "import tensorflow.keras\n",
    "tensorboard_callback = tensorflow.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/500\n",
      " 640/7000 [=>............................] - ETA: 2:37 - loss: 27926.1087 - accuracy: 0.0234"
     ]
    }
   ],
   "source": [
    "# Complie Model\n",
    "epochs = 500\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "model_fit = model.fit(X_train, y_train, validation_split=0.30, epochs=epochs, batch_size=batch_size, callbacks=[checkpointer, hist], verbose=1)\n",
    "\n",
    "model.save('models/model_128_9.h5')\n",
    "print(\"Save model successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####  LOADING AND EXTRACTING DATA   #####\n",
    "\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline\n",
    "def data_loader():\n",
    "    \n",
    "    # Load dataset file\n",
    "    data_frame = pd.read_csv('training.csv')\n",
    "    \n",
    "    data_frame['Image'] = data_frame['Image'].apply(lambda i: np.fromstring(i, sep=' '))\n",
    "    data_frame = data_frame.dropna()  # Get only the data with 15 keypoints\n",
    "   \n",
    "    # Extract Images pixel values\n",
    "    imgs_array = np.vstack(data_frame['Image'].values)/ 255.0\n",
    "    imgs_array = imgs_array.astype(np.float32)    # Normalize, target values to (0, 1)\n",
    "    imgs_array = imgs_array.reshape(-1, 96, 96, 1)\n",
    "        \n",
    "    # Extract labels (key point cords)\n",
    "    labels_array = data_frame[data_frame.columns[:-1]].values\n",
    "    labels_array = (labels_array - 48) / 48    # Normalize, traget cordinates to (-1, 1)\n",
    "    labels_array = labels_array.astype(np.float32) \n",
    "    \n",
    "    # shuffle the train data\n",
    "#     imgs_array, labels_array = shuffle(imgs_array, labels_array, random_state=9)  \n",
    "    \n",
    "    return imgs_array, labels_array\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "# This snippet is just to check/verify data\n",
    "imgs, labels = data_loader()\n",
    "print(imgs.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "n=0\n",
    "labels[n] = (labels[n]*48)+48\n",
    "image = np.squeeze(imgs[n])\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.plot(labels[n][::2], labels[n][1::2], 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = data_loader()\n",
    "print(\"Training datapoint shape: X_train.shape:{}\".format(X_train.shape))\n",
    "print(\"Training labels shape: y_train.shape:{}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def the_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, (3,3), padding='same', activation='relu', input_shape=X_train.shape[1:])) # Input shape: (96, 96, 1)\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    \n",
    "    model.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    \n",
    "    # Convert all values to 1D array\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(30))\n",
    "    \n",
    "    return model\n",
    "batch_size = 64\n",
    "\n",
    "model = the_model()\n",
    "hist = History()\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='checkpoint1.hdf5', \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complie Model\n",
    "epochs = 40\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "model_fit = model.fit(imgs, labels, validation_split=0.2, epochs=epochs, batch_size=batch_size, callbacks=[checkpointer, hist], verbose=1)\n",
    "\n",
    "model.save('model.h5')\n",
    "print(\"Save model successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "facialKeypointDetection_YT.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
